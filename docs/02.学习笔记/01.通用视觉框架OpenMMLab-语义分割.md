---
title: 《通用视觉框架OpenMMLab-语义分割》笔记
date: 2022-06-04 16:06:01
permalink: /notes/mmseg/
categories: 
  - 笔记
tags: 
  - 笔记
  - mmsegmentation
author: 
  name: liuyuan
  link: https://github.com/my-monster
---
# 语义分割基础知识
## 什么是语义分割
**任务**: 将图像按照物体的类别分割成不同的区域
**等价于**: 对每个像素进行分类
## 应用
无人汽车驾驶
人像分割
智能遥感
==医疗影像分析==
## 语义分割vs实例分割vs全景分割
![啦啦啦](https://img-blog.csdnimg.cn/95b9b185b91c424e94ee254415ee6c45.png)
**语义分割**
仅考虑像素的类别，不分割同一类别的不同实体
**实例分割**
分割不同的实体，仅考虑前景物体，不分割背景
**全景分割** = 语义分割+实例分割
背景仅考虑类别，前景需要区分实体

# 语义分割的基本思路
## 按颜色分割
**先验知识**
物体内部颜色相同，物体交界颜色变化
>问题：不同物体颜色可能相近，物体内也会有多种颜色
>解决办法：借助额外手段确定物体类别（如假设物体的形状、位置等）
## 逐像素分类
### FCN
#### 复用卷积计算
![在这里插入图片描述](https://img-blog.csdnimg.cn/bc0b739e89a1495db1c7d86468764e34.png)
>解决办法：复用卷积计算——使用跟滑窗同样大小的卷积核在原图上计算卷积
#### 全连接层的卷积化
![在这里插入图片描述](https://img-blog.csdnimg.cn/78c2fff0e8a84bf19ec1b37c72d45335.png)
> 问题：在做图像分割时，输入的原图可能时任意大小的，全连接层不能处理不同大小的图像，怎么解决这个问题？

![在这里插入图片描述](https://img-blog.csdnimg.cn/756b27aba3ac45d19cd4eda564245bc2.png)
>将全连接层转换为卷积层，对于任意大小的特征图，卷积核都可以与之卷积，它与前一层的 feature map 多大没有关系，因此全卷积网络可以输入任意大小的图像。
#### 预测图的升采样
![在这里插入图片描述](https://img-blog.csdnimg.cn/160a6d3f3d6147f893541321dbb74fae.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/4d62122356ac410695a16662726b3532.png)
>解决方案：
>1．双线性插值
>2．转置卷积:可学习的升采样层

##### 双线性插值
![在这里插入图片描述](https://img-blog.csdnimg.cn/fabf123278f94a8e8fc1ffb6976c3bf3.png)
之所以叫双线性插值是因为计算插值的时候会考虑x，y轴两个方向的变化。
![在这里插入图片描述](https://img-blog.csdnimg.cn/1843fb6bdaa44a2b91d9a59a67d28d31.png)

##### 卷积实现双线性插值
与其手动计算插值，不如利用卷积运算计算相应的插值，首先将原始数据散开，然后将双线性插值对应的卷积核（固定）与散开的数据进行卷积计算出空白位置的插值。
![在这里插入图片描述](https://img-blog.csdnimg.cn/4eb3251a5b784ec79745ba2792e00c2c.png)
##### 转置卷积（Transposed Convolution）
转置卷积与上述的卷积方法相同，不同的点在于置换卷积的卷积核是学习出来的，并非固定。
>理解过程：
>将卷积核表示为稀疏矩阵C，每一行向量表示在一个位置的卷积操作，0填充表示卷积核未覆盖到的区域。同时，对输入特征添加空洞，额外padding，然后展开为列向量，将稀疏矩阵与列向量进行转置卷积得到升采样的结果。（==转置卷积在形式上与卷积互逆，但数值结果没有关系。==）

![在这里插入图片描述](https://img-blog.csdnimg.cn/4e75517cc44044fd9bcfaaf0c177e12b.png)
下图为转置卷积的动态过程。
![在这里插入图片描述](https://img-blog.csdnimg.cn/img_convert/3e5023c469cccdc7c4242ac0022385ab.gif)
#### 基于多层级特征的上采样
>问题：
>仅仅应用全连接层卷积化和转置卷积进行上采样这两个技术并不足以很好的解决图像分割问题。基于多次卷积得到的高层特征要远小于原图，且细节丢失较为严重，我们只对高层特征图进行预测，然后再升采样到原图大小的预测图会较为粗糙。

![在这里插入图片描述](https://img-blog.csdnimg.cn/06bf7c88e4824cc4844de115c6e6025c.png)
>解决思路：
>结合低层次和高层次特征图。 
![在这里插入图片描述](https://img-blog.csdnimg.cn/e8ebdbcc01864775bb6de4617f81f0c4.png)
### UNet 2015
逐级融合高低层次特征。

![在这里插入图片描述](https://img-blog.csdnimg.cn/8593802f4b8b44989980fee56feb5067.png)

### PSPNet 2016
#### 上下文信息
在FCN中低层次的特征图只能看到图片中的一个小区域。
![在这里插入图片描述](https://img-blog.csdnimg.cn/3fa8719c332547809f9a214f87304ae7.png)
在这个小区域内判断物体的类别会有较大的误差，当我们给定这个小区域周围的图像（也称上下文）时，就可以很轻松判断出小区域内的问题类别，帮助我们做出更加准确的判断。
![在这里插入图片描述](https://img-blog.csdnimg.cn/dd672b650ef24c2597382e691329453c.png)
>解决方法：![在这里插入图片描述](https://img-blog.csdnimg.cn/fb4595545584403b88bb8a025bcc9507.png)
### DeepLab 系列
DeepLab是语义分割的又一系列工作，其主要贡献为:
·使用空洞卷积解决网络中的下采样问题
·使用条件随机场CRF 作为后处理手段，精细化分割图
·使用多尺度的空洞卷积(ASPP模块)捕捉上下文信息

![在这里插入图片描述](https://img-blog.csdnimg.cn/b5a395e6ade24635bcace3e36f9acb29.png)
#### 空洞卷积
![在这里插入图片描述](https://img-blog.csdnimg.cn/7053a8b53748412a8ce093fb9a4ff378.png)
空洞卷积 = 下采样 + 卷积运算
![在这里插入图片描述](https://img-blog.csdnimg.cn/cde9cdf3a0de4e41ab6a92edae25e2de.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/7842dc67ab854d9ba98d3460b0d98e1d.png)
#### 条件随机场 Conditional Random Field, CRF
>作用：产生更加精细的边界

![在这里插入图片描述](https://img-blog.csdnimg.cn/b0c9cf314222439a8a793c8b8b146ff6.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/77f99c1283c048bbb2b16677d6a7c3c9.png)

该能量函数同时考虑原图信息和网络输出的概率信息，原图信息包括原图颜色以及每个像素点的位置。
![在这里插入图片描述](https://img-blog.csdnimg.cn/7dd20de2013c40399e1f1e5fd5071d05.png)
#### 空间金字塔池化 Atrous Spatial Pyramid Pooling ASPP
![在这里插入图片描述](https://img-blog.csdnimg.cn/edead898d9fb49ee91286f42cdee52f8.png)
#### DeepLab v3+ 
![在这里插入图片描述](https://img-blog.csdnimg.cn/f290e10f421e4f3a8778a2fb2bc1e890.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/4b99b37be9694fd99018861de676d160.png)
# 语义分割算法总结
![在这里插入图片描述](https://img-blog.csdnimg.cn/448838c5084441878aa0897850761d8a.png)
# 语义分割模型的评估
比较预测与真值
![在这里插入图片描述](https://img-blog.csdnimg.cn/e09f3b273c43437a98f63006acd66e59.png)

![在这里插入图片描述](https://img-blog.csdnimg.cn/3240fa23c64a4f76aeb8e326eec99151.png)
# mmsegmentation语义分割框架
以PSPNet 网络为例，对使用 ResNet50V1c 的 PSPNet 的配置文件做了详细的注释说明。
```python
norm_cfg = dict(type='SyncBN', requires_grad=True)  # 分割框架通常使用 SyncBN
model = dict(
    type='EncoderDecoder',  # 分割器(segmentor)的名字
    pretrained='open-mmlab://resnet50_v1c',  # 将被加载的 ImageNet 预训练主干网络
    backbone=dict(
        type='ResNetV1c',  # 主干网络的类别。 可用选项请参考 mmseg/models/backbones/resnet.py
        depth=50,  # 主干网络的深度。通常为 50 和 101。
        num_stages=4,  # 主干网络状态(stages)的数目，这些状态产生的特征图作为后续的 head 的输入。
        out_indices=(0, 1, 2, 3),  # 每个状态产生的特征图输出的索引。
        dilations=(1, 1, 2, 4),  # 每一层(layer)的空心率(dilation rate)。
        strides=(1, 2, 1, 1),  # 每一层(layer)的步长(stride)。
        norm_cfg=dict(  # 归一化层(norm layer)的配置项。
            type='SyncBN',  # 归一化层的类别。通常是 SyncBN。
            requires_grad=True),   # 是否训练归一化里的 gamma 和 beta。
        norm_eval=False,  # 是否冻结 BN 里的统计项。
        style='pytorch',  # 主干网络的风格，'pytorch' 意思是步长为2的层为 3x3 卷积， 'caffe' 意思是步长为2的层为 1x1 卷积。
        contract_dilation=True),  # 当空洞 > 1, 是否压缩第一个空洞层。
    decode_head=dict(
        type='PSPHead',  # 解码头(decode head)的类别。 可用选项请参考 mmseg/models/decode_heads。
        in_channels=2048,  # 解码头的输入通道数。
        in_index=3,  # 被选择的特征图(feature map)的索引。
        channels=512,  # 解码头中间态(intermediate)的通道数。
        pool_scales=(1, 2, 3, 6),  # PSPHead 平均池化(avg pooling)的规模(scales)。 细节请参考文章内容。
        dropout_ratio=0.1,  # 进入最后分类层(classification layer)之前的 dropout 比例。
        num_classes=19,  # 分割前景的种类数目。 通常情况下，cityscapes 为19，VOC为21，ADE20k 为150。
        norm_cfg=dict(type='SyncBN', requires_grad=True),  # 归一化层的配置项。
        align_corners=False,  # 解码里调整大小(resize)的 align_corners 参数。
        loss_decode=dict(  # 解码头(decode_head)里的损失函数的配置项。
            type='CrossEntropyLoss',  # 在分割里使用的损失函数的类别。
            use_sigmoid=False,  # 在分割里是否使用 sigmoid 激活。
            loss_weight=1.0)),  # 解码头里损失的权重。
    auxiliary_head=dict(
        type='FCNHead',  # 辅助头(auxiliary head)的种类。可用选项请参考 mmseg/models/decode_heads。
        in_channels=1024,  # 辅助头的输入通道数。
        in_index=2,  # 被选择的特征图(feature map)的索引。
        channels=256,  # 辅助头中间态(intermediate)的通道数。
        num_convs=1,  # FCNHead 里卷积(convs)的数目. 辅助头里通常为1。
        concat_input=False,  # 在分类层(classification layer)之前是否连接(concat)输入和卷积的输出。
        dropout_ratio=0.1,  # 进入最后分类层(classification layer)之前的 dropout 比例。
        num_classes=19,  # 分割前景的种类数目。 通常情况下，cityscapes 为19，VOC为21，ADE20k 为150。
        norm_cfg=dict(type='SyncBN', requires_grad=True),  # 归一化层的配置项。
        align_corners=False,  # 解码里调整大小(resize)的 align_corners 参数。
        loss_decode=dict(  # 辅助头(auxiliary head)里的损失函数的配置项。
            type='CrossEntropyLoss',  # 在分割里使用的损失函数的类别。
            use_sigmoid=False,  # 在分割里是否使用 sigmoid 激活。
            loss_weight=0.4)))  # 辅助头里损失的权重。默认设置为0.4。
train_cfg = dict()  # train_cfg 当前仅是一个占位符。
test_cfg = dict(mode='whole')  # 测试模式， 选项是 'whole' 和 'sliding'. 'whole': 整张图像全卷积(fully-convolutional)测试。 'sliding': 图像上做滑动裁剪窗口(sliding crop window)。
dataset_type = 'CityscapesDataset'  # 数据集类型，这将被用来定义数据集。
data_root = 'data/cityscapes/'  # 数据的根路径。
img_norm_cfg = dict(  # 图像归一化配置，用来归一化输入的图像。
    mean=[123.675, 116.28, 103.53],  # 预训练里用于预训练主干网络模型的平均值。
    std=[58.395, 57.12, 57.375],  # 预训练里用于预训练主干网络模型的标准差。
    to_rgb=True)  # 预训练里用于预训练主干网络的图像的通道顺序。
crop_size = (512, 1024)  # 训练时的裁剪大小
train_pipeline = [  #训练流程
    dict(type='LoadImageFromFile'),  # 第1个流程，从文件路径里加载图像。
    dict(type='LoadAnnotations'),  # 第2个流程，对于当前图像，加载它的注释信息。
    dict(type='Resize',  # 变化图像和其注释大小的数据增广的流程。
        img_scale=(2048, 1024),  # 图像的最大规模。
        ratio_range=(0.5, 2.0)), # 数据增广的比例范围。
    dict(type='RandomCrop',  # 随机裁剪当前图像和其注释大小的数据增广的流程。
        crop_size=(512, 1024),  # 随机裁剪图像生成 patch 的大小。
        cat_max_ratio=0.75),  # 单个类别可以填充的最大区域的比例。
    dict(
        type='RandomFlip',  # 翻转图像和其注释大小的数据增广的流程。
        flip_ratio=0.5),  # 翻转图像的概率
    dict(type='PhotoMetricDistortion'),  # 光学上使用一些方法扭曲当前图像和其注释的数据增广的流程。
    dict(
        type='Normalize',  # 归一化当前图像的数据增广的流程。
        mean=[123.675, 116.28, 103.53],  # 这些键与 img_norm_cfg 一致，因为 img_norm_cfg 被
        std=[58.395, 57.12, 57.375],  # 用作参数。
        to_rgb=True),
    dict(type='Pad',  # 填充当前图像到指定大小的数据增广的流程。
        size=(512, 1024),  # 填充的图像大小。
        pad_val=0,  # 图像的填充值。
        seg_pad_val=255),  # 'gt_semantic_seg'的填充值。
    dict(type='DefaultFormatBundle'),  # 流程里收集数据的默认格式捆。
    dict(type='Collect',  # 决定数据里哪些键被传递到分割器里的流程。
        keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),  # 第1个流程，从文件路径里加载图像。
    dict(
        type='MultiScaleFlipAug',  # 封装测试时数据增广(test time augmentations)。
        img_scale=(2048, 1024),  # 决定测试时可改变图像的最大规模。用于改变图像大小的流程。
        flip=False,  # 测试时是否翻转图像。
        transforms=[
            dict(type='Resize',  # 使用改变图像大小的数据增广。
                 keep_ratio=True),  # 是否保持宽和高的比例，这里的图像比例设置将覆盖上面的图像规模大小的设置。
            dict(type='RandomFlip'),  # 考虑到 RandomFlip 已经被添加到流程里，当 flip=False 时它将不被使用。
            dict(
                type='Normalize',  # 归一化配置项，值来自 img_norm_cfg。
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', # 将图像转为张量
                keys=['img']),
            dict(type='Collect', # 收集测试时必须的键的收集流程。
                keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=2,  # 单个 GPU 的 Batch size
    workers_per_gpu=2,  # 单个 GPU 分配的数据加载线程数
    train=dict(  # 训练数据集配置
        type='CityscapesDataset',  # 数据集的类别, 细节参考自 mmseg/datasets/。
        data_root='data/cityscapes/',  # 数据集的根目录。
        img_dir='leftImg8bit/train',  # 数据集图像的文件夹。
        ann_dir='gtFine/train',  # 数据集注释的文件夹。
        pipeline=[  # 流程， 由之前创建的 train_pipeline 传递进来。
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(
                type='Resize', img_scale=(2048, 1024), ratio_range=(0.5, 2.0)),
            dict(type='RandomCrop', crop_size=(512, 1024), cat_max_ratio=0.75),
            dict(type='RandomFlip', flip_ratio=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size=(512, 1024), pad_val=0, seg_pad_val=255),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_semantic_seg'])
        ]),
    val=dict(  # 验证数据集的配置
        type='CityscapesDataset',
        data_root='data/cityscapes/',
        img_dir='leftImg8bit/val',
        ann_dir='gtFine/val',
        pipeline=[  # 由之前创建的 test_pipeline 传递的流程。
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 1024),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='CityscapesDataset',
        data_root='data/cityscapes/',
        img_dir='leftImg8bit/val',
        ann_dir='gtFine/val',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 1024),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(  # 注册日志钩 (register logger hook) 的配置文件。
    interval=50,  # 打印日志的间隔
    hooks=[
        # dict(type='TensorboardLoggerHook')  # 同样支持 Tensorboard 日志
        dict(type='TextLoggerHook', by_epoch=False)
    ])
dist_params = dict(backend='nccl')  # 用于设置分布式训练的参数，端口也同样可被设置。
log_level = 'INFO'  # 日志的级别。
load_from = None  # 从一个给定路径里加载模型作为预训练模型，它并不会消耗训练时间。
resume_from = None  # 从给定路径里恢复检查点(checkpoints)，训练模式将从检查点保存的轮次开始恢复训练。
workflow = [('train', 1)]  # runner 的工作流程。 [('train', 1)] 意思是只有一个工作流程而且工作流程 'train' 仅执行一次。根据 `runner.max_iters` 工作流程训练模型的迭代轮数为40000次。
cudnn_benchmark = True  # 是否是使用 cudnn_benchmark 去加速，它对于固定输入大小的可以提高训练速度。
optimizer = dict(  # 用于构建优化器的配置文件。支持 PyTorch 中的所有优化器，同时它们的参数与PyTorch里的优化器参数一致。
    type='SGD',  # 优化器种类，更多细节可参考 https://github.com/open-mmlab/mmcv/blob/master/mmcv/runner/optimizer/default_constructor.py#L13。
    lr=0.01,  # 优化器的学习率，参数的使用细节请参照对应的 PyTorch 文档。
    momentum=0.9,  # 动量 (Momentum)
    weight_decay=0.0005)  # SGD 的衰减权重 (weight decay)。
optimizer_config = dict()  # 用于构建优化器钩 (optimizer hook) 的配置文件，执行细节请参考 https://github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/optimizer.py#L8。
lr_config = dict(
    policy='poly',  # 调度流程的策略，同样支持 Step, CosineAnnealing, Cyclic 等. 请从 https://github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/lr_updater.py#L9 参考 LrUpdater 的细节。
    power=0.9,  # 多项式衰减 (polynomial decay) 的幂。
    min_lr=0.0001,  # 用来稳定训练的最小学习率。
    by_epoch=False)  # 是否按照每个 epoch 去算学习率。
runner = dict(
    type='IterBasedRunner', # 将使用的 runner 的类别 (例如 IterBasedRunner 或 EpochBasedRunner)。
    max_iters=40000) # 全部迭代轮数大小，对于 EpochBasedRunner 使用 `max_epochs` 。
checkpoint_config = dict(  # 设置检查点钩子 (checkpoint hook) 的配置文件。执行时请参考 https://github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/checkpoint.py。
    by_epoch=False,  # 是否按照每个 epoch 去算 runner。
    interval=4000)  # 保存的间隔
evaluation = dict(  # 构建评估钩 (evaluation hook) 的配置文件。细节请参考 mmseg/core/evaluation/eval_hook.py。
    interval=4000,  # 评估的间歇点
    metric='mIoU')  # 评估的指标


```

>一些模块的详细解释
>![在这里插入图片描述](https://img-blog.csdnimg.cn/3b856ba969b14bbc97160edc6482e2d8.png)
>![在这里插入图片描述](https://img-blog.csdnimg.cn/fa556b6d547b4057a45bce8463dddad8.png)
ResNet 50 完整结构
![在这里插入图片描述](https://img-blog.csdnimg.cn/029914a46a7e4c35a28f86c63289b354.png)
上图中，每级残差模块（stage）中的第一个残差模块通常会包含一个降采样层，具体而言就是在卷积上使用1乘1，步长为2的卷积；特征图上只有四分之一的响应参与卷积运算，四分之三的信息丢失。==针对这个问题提出以下不同的结构。==

![在这里插入图片描述](https://img-blog.csdnimg.cn/87069ad142c54162b9d7c79003727ed6.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/e268198856164f88aa40316ec6a32cc3.png)
辅助解码头的配置
![在这里插入图片描述](https://img-blog.csdnimg.cn/cf4776a90c644eb08996d092cb891c70.png)
数据处理流水线
![在这里插入图片描述](https://img-blog.csdnimg.cn/f92ca9d67b3e4f199beff0b6b5aed2fb.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/8ab3140d693f45c4baea7e0366505a53.png)

