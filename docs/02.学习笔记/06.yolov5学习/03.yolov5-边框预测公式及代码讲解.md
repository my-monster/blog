# 边框预测公式
![在这里插入图片描述](https://img-blog.csdnimg.cn/4504eb357cdc4c77b8344e45d408eb43.png)
> cx，cy为当前预测的Tensor对应的grid坐标，即**左上角坐标**。
## 代码实现
### model -> yolo.py -> class Detect -> forward

```python
 def forward(self, x):
     z = []  # inference output
     for i in range(self.nl):
         x[i] = self.m[i](x[i])  # conv
         bs, _, ny, nx = x[i].shape  # x(bs,255,20,20) to x(bs,3,20,20,85)
         x[i] = x[i].view(bs, self.na, self.no, ny, nx).permute(0, 1, 3, 4, 2).contiguous()

         if not self.training:  # inference
             if self.onnx_dynamic or self.grid[i].shape[2:4] != x[i].shape[2:4]:
                 self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)  # 计算grid，anchor_grid
			# 以下为具体实现
             y = x[i].sigmoid()  # σ() | sigmoid操作
             if self.inplace:
                 y[..., 0:2] = (y[..., 0:2] * 2 - 0.5 + self.grid[i]) * self.stride[i]  # xy | （2*σ(t)-0.5+c）* stride
                 y[..., 2:4] = (y[..., 2:4] * 2) ** 2 * self.anchor_grid[i]  # wh
             else:  # for YOLOv5 on AWS Inferentia https://github.com/ultralytics/yolov5/pull/2953
                 xy = (y[..., 0:2] * 2 - 0.5 + self.grid[i]) * self.stride[i]  # xy
                 wh = (y[..., 2:4] * 2) ** 2 * self.anchor_grid[i]  # wh
                 y = torch.cat((xy, wh, y[..., 4:]), -1)
             z.append(y.view(bs, -1, self.no))

     return x if self.training else (torch.cat(z, 1), x)
```

## 细节解析
### 中心点改进
![在这里插入图片描述](https://img-blog.csdnimg.cn/bd2ab3bb0be246aa9cd7d7ca5ba30197.png)
### 宽高改进
![在这里插入图片描述](https://img-blog.csdnimg.cn/6ee7a73dbd234bfb9a5b3b8e69356345.png)
>关联超参数：
>anchor_t: 4.0  # anchor-multiple threshold
>使得预测宽高在[1/4，4]之间。
### 正采样
**作用：扩充正样本**
![在这里插入图片描述](https://img-blog.csdnimg.cn/316359c1754042b39228d1543f5c92be.png)
>正样本概念是本文提出的，在yolov5中并没有这样定义。
>逻辑思路：假设yolov5网络中有8个正样本，经过正采样采样操作后会将原来正阳本上下左右四个邻近的区域（通常选取两个距离中心点最近的两个区域）也看成是正样本。

![在这里插入图片描述](https://img-blog.csdnimg.cn/21b262f6b3964697a5dcad099176f53b.png)
### 正采样原理
将ground true中xywh*对应的尺寸获得对应尺寸的标注信息（例如下图xy均乘8）
![在这里插入图片描述](https://img-blog.csdnimg.cn/94792d7d69134221a85d6a1a5dde5404.png)

```python
gxy = t[:, 2:4]  # grid xy
gxi = gain[[2, 3]] - gxy  # inverse
j, k = ((gxy % 1 < g) & (gxy > 1)).T
l, m = ((gxi % 1 < g) & (gxi > 1)).T
```
![在这里插入图片描述](https://img-blog.csdnimg.cn/8af52de622b645b9b45fbb46d352edf6.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/efa923d02c624d69a4c11aaef403ae4a.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/2a17fb1ddd8946f9bd9cb696e812ae5a.png)

![在这里插入图片描述](https://img-blog.csdnimg.cn/c67842dd99a744c69e152a5eb17b17c1.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/51d5496c64c14bee9916761458bbb46d.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/a5103a4d476f44619b7836754a70e442.png)

![在这里插入图片描述](https://img-blog.csdnimg.cn/9cebc5c958174b69b211fee04c8c513a.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/517300adbe3647f8a3c380c23fb75ce5.png)


![在这里插入图片描述](https://img-blog.csdnimg.cn/900efcd921304b1f86a09bda709fa22f.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/10a5c8c4a8264eb58299f97c9fd839a6.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/46b94e4461dc4e27b96faec7c6e43035.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/3a6c22079ffc433abcdbcb1abef48780.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/cffd31845aff49c289b27672944ecc51.png)





#### 代码实现（utils -> loss.py -> class ComputeLoss -> build_targets）

```python
def build_targets(self, p, targets):
    # Build targets for compute_loss(), input targets(image id,class,x,y,w,h) | p：三层预测Tensor； target：ground true
    na, nt = self.na, targets.shape[0]  # number of anchors, targets
    tcls, tbox, indices, anch = [], [], [], []
    gain = torch.ones(7, device=targets.device)  # normalized to gridspace gain
    ai = torch.arange(na, device=targets.device).float().view(na, 1).repeat(1, nt)  # same as .repeat_interleave(nt)
    targets = torch.cat((targets.repeat(na, 1, 1), ai[:, :, None]), 2)  # append anchor indices

    g = 0.5  # bias
    off = torch.tensor([[0, 0],
                        [1, 0], [0, 1], [-1, 0], [0, -1],  # j,k,l,m
                        # [1, 1], [1, -1], [-1, 1], [-1, -1],  # jk,jm,lk,lm
                        ], device=targets.device).float() * g  # offsets

    for i in range(self.nl):
        anchors = self.anchors[i]
        gain[2:6] = torch.tensor(p[i].shape)[[3, 2, 3, 2]]  # xyxy gain

        # Match targets to anchors
        t = targets * gain  # 将ground true中xywh*对应的尺寸获得对应尺寸的标注信息
        if nt:
            # Matches | 控制预测wh与ground true的比例
            r = t[:, :, 4:6] / anchors[:, None]  # wh ratio
            j = torch.max(r, 1 / r).max(2)[0] < self.hyp['anchor_t']  # compare
            # j = wh_iou(anchors, t[:, 4:6]) > model.hyp['iou_t']  # iou(3,n)=wh_iou(anchors(3,2), gwh(n,2))
            t = t[j]  # filter

            # Offsets | 获取正样本周围的样本，扩充正样本
            gxy = t[:, 2:4]  # grid xy | 缩放之后中心点坐标
            gxi = gain[[2, 3]] - gxy  # inverse | 以右上角的点为原点，重新获得中心点坐标
            j, k = ((gxy % 1 < g) & (gxy > 1)).T
            l, m = ((gxi % 1 < g) & (gxi > 1)).T  # 判断是否为可扩充样本
            j = torch.stack((torch.ones_like(j), j, k, l, m))  # 
            t = t.repeat((5, 1, 1))[j]
            offsets = (torch.zeros_like(gxy)[None] + off[:, None])[j]
        else:
            t = targets[0]
            offsets = 0

        # Define
        b, c = t[:, :2].long().T  # image, class
        gxy = t[:, 2:4]  # grid xy
        gwh = t[:, 4:6]  # grid wh
        gij = (gxy - offsets).long()  # 等到正采样之后的坐标
        gi, gj = gij.T  # grid xy indices

        # Append
        a = t[:, 6].long()  # anchor indices
        indices.append((b, a, gj.clamp_(0, gain[3] - 1), gi.clamp_(0, gain[2] - 1)))  # image, anchor, grid indices
        tbox.append(torch.cat((gxy - gij, gwh), 1))  # box | 将正采样之后扩充的正样本添加到原来的样本中
        anch.append(anchors[a])  # anchors
        tcls.append(c)  # class

    return tcls, tbox, indices, anch
```


